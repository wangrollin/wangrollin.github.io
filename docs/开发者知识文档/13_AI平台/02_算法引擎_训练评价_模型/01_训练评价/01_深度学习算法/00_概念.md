
- 反向传播 -- 更新梯度
- 梯度下降（gradient descent）
- 梯度消失
- 损失函数（loss function）
- 交叉熵
- 绝对误差
- 骨干网 backbone：在神经网络中，尤其是CV领域，一般先对图像进行特征提取（常见的有vggnet，resnet，谷歌的inception），这一部分是整个CV任务的根基，因为后续的下游任务都是基于提取出来的图像特征去做文章（比如分类，生成等等）
- sigmoid


机器学习需要人来标注特征。深度学习的特点，可以直接从数据中自己学习出底层特征

perceptron：一个神经节点
active_function(x1w1+x2w2+1w0 bias)=output y
y=g(z)
- XW
- bias
- g 非线性激活函数（激活函数都是非线性的）（目的：为网络引入非线性，因为NN解决的都是非线性的问题）
  - sigmoid function (0,1)
  - hyperbolic tangent
  - rectified linear unit (ReLU)

前向传播， forward propagation
- 乘起来
- 合并起来
- 激活